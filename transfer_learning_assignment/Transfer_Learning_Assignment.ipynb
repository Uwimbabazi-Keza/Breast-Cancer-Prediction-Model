{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uwimbabazi-Keza/Breast-Cancer-Prediction-Model/blob/main/Transfer_Learning_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWW8XCJnIGrY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'cbis-ddsm-breast-cancer-image-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1115384%2F1873742%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240521%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240521T043320Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D55f8752bd48a630e3fdb2eff6fd1b45d02d29b439d6e71764b3100a5f8ab78999cbb69e0bab44ec1d207bd82182f001e3e5e42f02a4e73d97dcdf23fde33f35923319307ba0091a6a81203a34005c99ea75e76c06a0e182a2b8cc603cf8604e123922a341893bc3e4469d2f8060f7bebaddbb1769cdaad874582a9861fe82430d971b4ad6c0e53a0a6b308e5da09106bd69b1da6983053f4757a65080637a3a4d577e02844a4c516927a908df655d3f4c4858f97c653e4c70c64fe677bf43fd402bbe80c9a4a25371772a7ccfb6d5d8297cada12e6851e3247022bb32c547d42e03e02228258cb98d315a5c29369b53077774ee5933aded8a61cfe5f04412230,mobilenet-v1/tensorflow2/100-224-classification/2:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F1585%2F1950%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240521%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240521T043320Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D78fd5e70ae53091e934d7e4443c40cee67335692c78c7ce59f79aee0b4fb3590dd6caeb494714a230367b8e28dc3fc1fde506ee7170904ad167928e0bdb710368a9140896259ae1f34912e8c27fa69659b69bb176c6fdc211ff05df5462a5bf64050f36e0393fb0b389029af67a1f470cde606d9df18ef5aa4e819d8f3f8e81e30d75cb43e8e800c1365ff3e6f9f44a38e2fb7b3993c56cfd6738df6b3a44dffedf1d922c20506fbc619cb96835a256703be5b15da67f0234370e51c5e3aca1bb0fc1531f220e3d0202b01e3bd0d4d1f3a890f713889f605e1fc852b1522092e4ec272a8d26a69e6bf6713f9824f2c391ddccee72555dcfd41adb47ae06200a3'\n",
        "\n",
        "COLAB_DATA_PATH = '/content/data'\n",
        "COLAB_CLASS_PATH = '/content/class'\n",
        "\n",
        "shutil.rmtree(COLAB_DATA_PATH, ignore_errors=True)\n",
        "os.makedirs(COLAB_DATA_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(COLAB_CLASS_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(COLAB_DATA_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "                with ZipFile(tfile) as zfile:\n",
        "                    zfile.extractall(destination_path)\n",
        "            else:\n",
        "                with tarfile.open(tfile.name) as tarfile:\n",
        "                    tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "zpwP-xihs_Gl",
        "outputId": "35a83a8d-0ce5-4748-9240-4fc1354e78fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>keras.src.layers.regularization.dropout.Dropout</b><br/>def error_handler(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/keras/src/layers/regularization/dropout.py</a>Applies Dropout to the input.\n",
              "\n",
              "The Dropout layer randomly sets input units to 0 with a frequency of `rate`\n",
              "at each step during training time, which helps prevent overfitting.\n",
              "Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over\n",
              "all inputs is unchanged.\n",
              "\n",
              "Note that the Dropout layer only applies when `training` is set to True\n",
              "such that no values are dropped during inference. When using `model.fit`,\n",
              "`training` will be appropriately set to True automatically, and in other\n",
              "contexts, you can set the kwarg explicitly to True when calling the layer.\n",
              "\n",
              "(This is in contrast to setting `trainable=False` for a Dropout layer.\n",
              "`trainable` does not affect the layer&#x27;s behavior, as Dropout does\n",
              "not have any variables/weights that can be frozen during training.)\n",
              "\n",
              "&gt;&gt;&gt; tf.random.set_seed(0)\n",
              "&gt;&gt;&gt; layer = tf.keras.layers.Dropout(.2, input_shape=(2,))\n",
              "&gt;&gt;&gt; data = np.arange(10).reshape(5, 2).astype(np.float32)\n",
              "&gt;&gt;&gt; print(data)\n",
              "[[0. 1.]\n",
              " [2. 3.]\n",
              " [4. 5.]\n",
              " [6. 7.]\n",
              " [8. 9.]]\n",
              "&gt;&gt;&gt; outputs = layer(data, training=True)\n",
              "&gt;&gt;&gt; print(outputs)\n",
              "tf.Tensor(\n",
              "[[ 0.    1.25]\n",
              " [ 2.5   3.75]\n",
              " [ 5.    6.25]\n",
              " [ 7.5   8.75]\n",
              " [10.    0.  ]], shape=(5, 2), dtype=float32)\n",
              "\n",
              "Args:\n",
              "  rate: Float between 0 and 1. Fraction of the input units to drop.\n",
              "  noise_shape: 1D integer tensor representing the shape of the\n",
              "    binary dropout mask that will be multiplied with the input.\n",
              "    For instance, if your inputs have shape\n",
              "    `(batch_size, timesteps, features)` and\n",
              "    you want the dropout mask to be the same for all timesteps,\n",
              "    you can use `noise_shape=(batch_size, 1, features)`.\n",
              "  seed: A Python integer to use as random seed.\n",
              "\n",
              "Call arguments:\n",
              "  inputs: Input tensor (of any rank).\n",
              "  training: Python boolean indicating whether the layer should behave in\n",
              "    training mode (adding dropout) or in inference mode (doing nothing).</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 29);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "keras.src.layers.regularization.dropout.Dropout"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, Activation, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
        "Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0trD-5ya0W2"
      },
      "outputs": [],
      "source": [
        "csv_path = '/content/data/cbis-ddsm-breast-cancer-image-dataset/csv/meta.csv'\n",
        "df_meta = pd.read_csv(csv_path)\n",
        "\n",
        "dicom_data_path = '/content/data/cbis-ddsm-breast-cancer-image-dataset/csv/dicom_info.csv'\n",
        "dicom_data = pd.read_csv(dicom_data_path)\n",
        "\n",
        "image_dir = '/content/data/cbis-ddsm-breast-cancer-image-dataset/jpeg'\n",
        "full_mammogram_images = dicom_data[dicom_data.SeriesDescription == 'full mammogram images'].image_path\n",
        "cropped_images = dicom_data[dicom_data.SeriesDescription == 'cropped images'].image_path\n",
        "roi_mask_images = dicom_data[dicom_data.SeriesDescription == 'ROI mask images'].image_path\n",
        "\n",
        "full_mammogram_images = full_mammogram_images.apply(lambda x: x.replace('CBIS-DDSM/jpeg', image_dir))\n",
        "cropped_images = cropped_images.apply(lambda x: x.replace('CBIS-DDSM/jpeg', image_dir))\n",
        "roi_mask_images = roi_mask_images.apply(lambda x: x.replace('CBIS-DDSM/jpeg', image_dir))\n",
        "full_mammogram_images.iloc[0]\n",
        "\n",
        "full_mammogram_dict = dict()\n",
        "cropped_dict = dict()\n",
        "roi_mask_dict = dict()\n",
        "\n",
        "for dicom in full_mammogram_images:\n",
        "    # print(dicom)\n",
        "    key = dicom.split(\"/\")[5]\n",
        "    # print(key)\n",
        "    full_mammogram_dict[key] = dicom\n",
        "for dicom in cropped_images:\n",
        "    key = dicom.split(\"/\")[5]\n",
        "    cropped_dict[key] = dicom\n",
        "for dicom in roi_mask_images:\n",
        "    key = dicom.split(\"/\")[5]\n",
        "    roi_mask_dict[key] = dicom\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVbr7DQUcGRl"
      },
      "outputs": [],
      "source": [
        "mass_train_data = pd.read_csv('/content/data/cbis-ddsm-breast-cancer-image-dataset/csv/mass_case_description_train_set.csv')\n",
        "mass_test_data = pd.read_csv('/content/data/cbis-ddsm-breast-cancer-image-dataset/csv/mass_case_description_test_set.csv')\n",
        "calc_train_data = pd.read_csv('/content/data/cbis-ddsm-breast-cancer-image-dataset/csv/calc_case_description_train_set.csv')\n",
        "calc_test_data = pd.read_csv('/content/data/cbis-ddsm-breast-cancer-image-dataset/csv/calc_case_description_test_set.csv')\n",
        "\n",
        "def fix_image_path_mass(dataset):\n",
        "    for i, img in enumerate(dataset.values):\n",
        "        img_name = img[11].split(\"/\")[2]\n",
        "        if img_name in full_mammogram_dict:\n",
        "            dataset.iloc[i, 11] = full_mammogram_dict[img_name]\n",
        "\n",
        "        img_name = img[12].split(\"/\")[2]\n",
        "        if img_name in cropped_dict:\n",
        "            dataset.iloc[i, 12] = cropped_dict[img_name]\n",
        "\n",
        "        img_name = img[13].split(\"/\")[2]\n",
        "        if img_name in roi_mask_dict:\n",
        "            dataset.iloc[i, 13] = roi_mask_dict[img_name]\n",
        "\n",
        "fix_image_path_mass(mass_test_data)\n",
        "fix_image_path_mass(mass_train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG1uY83cciwL"
      },
      "outputs": [],
      "source": [
        "rename_columns = {\n",
        "    'left or right breast': 'left_or_right_breast',\n",
        "    'image view': 'image_view',\n",
        "    'abnormality id': 'abnormality_id',\n",
        "    'abnormality type': 'abnormality_type',\n",
        "    'mass shape': 'mass_shape',\n",
        "    'mass margins': 'mass_margins',\n",
        "    'image file path': 'image_file_path',\n",
        "    'cropped image file path': 'cropped_image_file_path',\n",
        "    'ROI mask file path': 'ROI_mask_file_path'\n",
        "}\n",
        "\n",
        "mass_train = mass_train_data.rename(columns=rename_columns)\n",
        "mass_test = mass_test_data.rename(columns=rename_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0C__YSbcxSZ"
      },
      "outputs": [],
      "source": [
        "benign=mass_train[mass_train.pathology==\"BENIGN\"]\n",
        "benign_without_callback=mass_train[mass_train.pathology==\"BENIGN_WITHOUT_CALLBACK\"]\n",
        "malignant=mass_train[mass_train.pathology==\"MALIGNANT\"]\n",
        "\n",
        "benign_images=benign.image_file_path\n",
        "malignant_images=malignant.image_file_path\n",
        "benign_without_callback_images=benign_without_callback.image_file_path\n",
        "\n",
        "benign_path='/content/data/cbis-ddsm-breast-cancer-image-dataset/class/benign'\n",
        "benign_wcb_path='/content/data/cbis-ddsm-breast-cancer-image-dataset/class/benignwithoutcallback'\n",
        "malignant_path='/content/data/cbis-ddsm-breast-cancer-image-dataset/class/malignant'\n",
        "os.makedirs(benign_path,exist_ok=True)\n",
        "os.makedirs(malignant_path,exist_ok=True)\n",
        "\n",
        "for ben_path in benign_images:\n",
        "  img_filename1=os.path.basename(ben_path)\n",
        "  destination_path1=os.path.join(benign_path,img_filename1)\n",
        "  shutil.copy(ben_path,destination_path1)\n",
        "\n",
        "for mal_path in malignant_images:\n",
        "  img_filename1=os.path.basename(mal_path)\n",
        "  destination_path1=os.path.join(malignant_path,img_filename1)\n",
        "  shutil.copy(mal_path,destination_path1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQi5XZDcc8AF"
      },
      "outputs": [],
      "source": [
        "# Define image dimensions\n",
        "IMG_HEIGHT, IMG_WIDTH = 512, 512\n",
        "CHANNELS = 1  # Grayscale\n",
        "\n",
        "# Define file paths for benign and malignant images (replace with your arrays)\n",
        "benign_file_paths = benign_images\n",
        "malignant_file_paths = malignant_images\n",
        "\n",
        "# Create DataFrame with file paths and labels\n",
        "benign_df = pd.DataFrame({'file_paths': benign_file_paths, 'labels': 'benign'})\n",
        "malignant_df = pd.DataFrame({'file_paths': malignant_file_paths, 'labels': 'malignant'})\n",
        "\n",
        "# Concatenate DataFrames\n",
        "df = pd.concat([benign_df, malignant_df], ignore_index=True)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24Y6IChNdAjm",
        "outputId": "033d1a6d-5c7f-4ec8-83f5-8ce73c245066"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 971 validated image filenames belonging to 2 classes.\n",
            "Found 243 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Create data generators for training and validation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='file_paths',\n",
        "    y_col='labels',\n",
        "    target_size=(512, 512),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    x_col='file_paths',\n",
        "    y_col='labels',\n",
        "    target_size=(512, 512),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCccFefSdG4U"
      },
      "outputs": [],
      "source": [
        "#Build Model\n",
        "def build_model(base_model):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS)))\n",
        "    model.add(Conv2D(3, (3, 3), padding='same'))  # Converting grayscale to RGB\n",
        "    model.add(base_model)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Load pre-trained models\n",
        "vgg16_base = VGG16(weights='imagenet', include_top=False)\n",
        "resnet50_base = ResNet50(weights='imagenet', include_top=False)\n",
        "inceptionv3_base = InceptionV3(weights='imagenet', include_top=False)\n",
        "\n",
        "# Freeze the layers of the base models\n",
        "for layer in vgg16_base.layers:\n",
        "    layer.trainable = False\n",
        "for layer in resnet50_base.layers:\n",
        "    layer.trainable = False\n",
        "for layer in inceptionv3_base.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Build models with the base models\n",
        "vgg16_model = build_model(vgg16_base)\n",
        "resnet50_model = build_model(resnet50_base)\n",
        "inceptionv3_model = build_model(inceptionv3_base)\n",
        "\n",
        "# Compile the models\n",
        "vgg16_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
        "resnet50_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
        "inceptionv3_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuPjgIT_zzNq",
        "outputId": "d5f91423-6b72-42fb-f2bd-7c8d8d2b1330"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            " 6/31 [====>.........................] - ETA: 1:24:33 - loss: 0.7075 - accuracy: 0.5781 - precision: 0.5867 - recall: 0.8224"
          ]
        }
      ],
      "source": [
        "# Define callbacks\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min'),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Train VGG16 model\n",
        "history_vgg16 = vgg16_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=3,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Train ResNet50 model\n",
        "history_resnet50 = resnet50_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=3,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Train InceptionV3 model\n",
        "history_inceptionv3 = inceptionv3_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=3,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLaPSyvJp9ft"
      },
      "outputs": [],
      "source": [
        "# Evaluate models\n",
        "vgg16_eval = vgg16_model.evaluate(val_generator)\n",
        "resnet50_eval = resnet50_model.evaluate(val_generator)\n",
        "inceptionv3_eval = inceptionv3_model.evaluate(val_generator)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"VGG16 - Accuracy: {:.2f}, Loss: {:.2f}, Precision: {:.2f}, Recall: {:.2f}\".format(vgg16_eval[1], vgg16_eval[0], vgg16_eval[2], vgg16_eval[3]))\n",
        "print(\"ResNet50 - Accuracy: {:.2f}, Loss: {:.2f}, Precision: {:.2f}, Recall: {:.2f}\".format(resnet50_eval[1], resnet50_eval[0], resnet50_eval[2], resnet50_eval[3]))\n",
        "print(\"InceptionV3 - Accuracy: {:.2f}, Loss: {:.2f}, Precision: {:.2f}, Recall: {:.2f}\".format(inceptionv3_eval[1], inceptionv3_eval[0], inceptionv3_eval[2], inceptionv3_eval[3]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geDVS4o-j0ZB"
      },
      "outputs": [],
      "source": [
        "# Save models\n",
        "vgg16_model.save('vgg16_breast_cancer_model.keras')\n",
        "resnet50_model.save('resnet50_breast_cancer_model.keras')\n",
        "inceptionv3_model.save('inceptionv3_breast_cancer_model.keras')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtRiWn2/y/VJSyYfwoM4BI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}